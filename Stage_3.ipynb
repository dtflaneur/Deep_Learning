{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing packages\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "import os\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import gc\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "import pretrainedmodels\n",
    "from torchvision.models import *\n",
    "from fastai.vision.models import *\n",
    "from fastai.vision.learner import model_meta\n",
    "\n",
    "from utils import *\n",
    "import sys\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "# torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/ubuntu/Documents/ELA/'\n",
    "path = '/home/ubuntu/share/stage-3/stage3_image_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "def convert_to_ela_image(path, folder, quality):\n",
    "    filename = path\n",
    "    ela_filename = f'/home/ubuntu/Documents/ELA2/{folder}/'\n",
    "    resaved_filename = '/home/ubuntu/Documents/temp.jpg'\n",
    "    \n",
    "    fname = filename.split('/')[-1]\n",
    "    ela_filename = ela_filename + fname\n",
    "    if(os.path.isfile(ela_filename)):\n",
    "        return\n",
    "#     print(ela_filename)\n",
    "    im = Image.open(filename).convert('RGB')\n",
    "    im.save(resaved_filename, 'JPEG', quality=quality)\n",
    "    resaved_im = Image.open(resaved_filename)\n",
    "    \n",
    "    ela_im = ImageChops.difference(im, resaved_im)\n",
    "    \n",
    "    extrema = ela_im.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "    ela_im = ela_im.resize((512, 512))\n",
    "    ela_im.save(ela_filename)\n",
    "    \n",
    "    return ela_im\n",
    "\n",
    "# Generate/Save ELA files for the train/test images.\n",
    "def generate_ela_files(files, is_train = False, labels = None):\n",
    "    if(is_train):\n",
    "        for f,l in tqdm(zip(files, labels)):\n",
    "            convert_to_ela_image(f,f'train/{l}', 90)\n",
    "    else:\n",
    "        print(len(files))\n",
    "        for f in tqdm(files):\n",
    "#             print(f)\n",
    "            convert_to_ela_image(f, 'train/fake', 90)\n",
    "    \n",
    "# Getting balanced set for train/validation\n",
    "def get_balanced_data(l_real, l_fake):\n",
    "    l_fake_sampled = np.random.choice(l_fake, len(l_real), replace = False)\n",
    "    files = l_real + list(l_fake_sampled)\n",
    "    labels = ['real']*len(l_real) + ['fake']*len(l_fake_sampled)\n",
    "    assert(len(files) == len(labels))\n",
    "    return files,labels\n",
    "\n",
    "def get_predictions(learn, is_test = False):\n",
    "    if(is_test):\n",
    "        log_preds = learn.predict(is_test)\n",
    "        preds = np.argmax(log_preds, axis=1)\n",
    "        probs = np.exp(log_preds)\n",
    "    else:\n",
    "        log_preds, y = learn.TTA()\n",
    "        probs = np.mean(np.exp(log_preds),0)\n",
    "        print(accuracy_np(probs,y))\n",
    "        preds = np.argmax(probs, axis=1)  # from log probabilities to 0 or 1ts\n",
    "        from sklearn.metrics import f1_score\n",
    "        print('F1_score: ', f1_score(y,preds,average='weighted'))\n",
    "        \n",
    "def get_metrics(y, preds):\n",
    "    from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "    print('F1_score: ', f1_score(y,preds,average='weighted'))\n",
    "    print('Accuracy: ', accuracy_score(y,preds))\n",
    "    print(confusion_matrix(y,preds))\n",
    "    \n",
    "def get_files(l_real, l_fake):\n",
    "    files = [path+'/'.join(x.split('/')[-3:]) for x in l_real] + [path+'/'.join(x.split('/')[-3:]) for x in l_fake]\n",
    "    labels = ['real']*len(l_real) + ['fake']*len(l_fake)\n",
    "    return files, labels\n",
    "\n",
    "def xception(pretrained=True):\n",
    "    pretrained = 'imagenet+background' if pretrained else None\n",
    "    model = pretrainedmodels.__dict__['xception'](pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))\n",
    "\n",
    "def get_learner(model_name, data):\n",
    "    if('resnet' in model_name):\n",
    "        m = eval(model_name)\n",
    "        learn = create_cnn(data, m, metrics=accuracy)\n",
    "        return learn\n",
    "    else:\n",
    "        if('densenet' in model_name):\n",
    "            m = eval(model_name)\n",
    "            learn = create_cnn(data, m, pretrained=True, cut=-1, split_on=lambda m: (m[0][0][7],m[1]), metrics = accuracy)\n",
    "            return learn\n",
    "        elif(model_name == 'inceptionv4'):\n",
    "            learn = create_cnn(FakeData(), inceptionv4, pretrained=True, cut=-2, split_on=lambda m: (m[0][11], m[1]))\n",
    "        elif(model_name == 'xception'):\n",
    "            learn = create_cnn(data, xception, pretrained=True, cut = -1, split_on = lambda m: (m[0][11], m[1]))\n",
    "    return learn\n",
    "\n",
    "# Create 3 different balanced train sets \n",
    "## Each having same set of real images(7K) and diff fake ones (7K)\n",
    "## Remaining files are kept as holdout validation set\n",
    "def generate_multi_version():\n",
    "    path_n = '/home/ubuntu/share/stage-3/stage3_image_data/'\n",
    "    l_real = get_imlist(f'{path_n}train/real')\n",
    "    l_fake = get_imlist(f'{path_n}train/fake')\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    random.shuffle(l_real)\n",
    "    random.shuffle(l_fake)\n",
    "    train_real = l_real[:7000]\n",
    "    train_fake1 = l_fake[:7000]\n",
    "    train_fake2 = l_fake[7000:14000]\n",
    "    train_fake3 = l_fake[14000:21000]\n",
    "    val_fake = l_fake[21000:]\n",
    "    val_real = l_real[7000:]\n",
    "    train_label = ['real']*len(train_real) + ['fake']*len(train_fake1)\n",
    "    val_label = ['real']*len(val_real) + ['fake']*len(val_fake)\n",
    "    \n",
    "    train_files1 = train_real + train_fake1\n",
    "    train_files2 = train_real + train_fake2\n",
    "    train_files3 = train_real + train_fake3\n",
    "    val_files = val_real + val_fake\n",
    "    \n",
    "    \n",
    "    return [train_files1, train_files2, train_files3], train_label, val_files, val_label\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_real = get_imlist(f'{path}train/real')\n",
    "l_fake = get_imlist(f'{path}train/fake')\n",
    "test_files = get_imlist(f'{path}test/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8373, 23887, 5430)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_real), len(l_fake), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = l_real + l_fake\n",
    "labels = ['real']*len(l_real) + ['fake']*len(l_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16746it [54:01,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_ela_files(files, True, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5430/5430 [22:28<00:00,  4.03it/s]  \n"
     ]
    }
   ],
   "source": [
    "generate_ela_files(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files,labels = get_files(l_real,l_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_df = pd.DataFrame({'Files': files, 'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_all, train_label, val_files, val_label = generate_multi_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 14000 14000\n",
      "14000 (array(['fake', 'real'], dtype='<U4'), array([7000, 7000]))\n",
      "4260 4260 (array(['fake', 'real'], dtype='<U4'), array([2887, 1373]))\n"
     ]
    }
   ],
   "source": [
    "# Few sanity checks\n",
    "print(len(train_files_all[0]), len(train_files_all[1]), len(train_files_all[2]))\n",
    "print(len(train_label), np.unique(train_label, return_counts = True))\n",
    "print(len(val_files), len(val_label), np.unique(val_label, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['/home/ubuntu/Documents/ELA/' + '/'.join(x.split('/')[-3:]) for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    train_files_all[i] = ['/home/ubuntu/Documents/ELA2/' + '/'.join(x.split('/')[-3:]) for x in train_files_all[i]]\n",
    "val_files = ['/home/ubuntu/Documents/ELA2/' + '/'.join(x.split('/')[-3:]) for x in val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach\n",
    "## The aim was to get similar acc on all the 3 balanced set created at start - an indicator of model generalizing well on unseen data\n",
    "#### This decision was based on the observation that we had very diff val accuracies on diff samples of 'fake' used as train \n",
    "## Experimented on side to reach a final set of hp which seemed to give similar acc on all 3 val splits for respective train sets\n",
    "\n",
    "## Proceeded with progressive resizing to improve val acc further.\n",
    "\n",
    "## Entire above exercise was done on ELA images as well normal images.\n",
    "## Final submission ensemble of two. - this gave a good lift in f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:16 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.556275</th>\n",
       "    <th>0.522364</th>\n",
       "    <th>0.747429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.533718</th>\n",
       "    <th>0.514938</th>\n",
       "    <th>0.752286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.523318</th>\n",
       "    <th>0.509010</th>\n",
       "    <th>0.751143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.524286</th>\n",
       "    <th>0.507834</th>\n",
       "    <th>0.756000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:31 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.519596</th>\n",
       "    <th>0.501937</th>\n",
       "    <th>0.763714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.506621</th>\n",
       "    <th>0.498971</th>\n",
       "    <th>0.758857</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:30 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.508699</th>\n",
       "    <th>0.496347</th>\n",
       "    <th>0.763143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.506963</th>\n",
       "    <th>0.496946</th>\n",
       "    <th>0.760000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1st iter model on size 128\n",
    "files, labels = train_files_all[0], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "# Removing cropping as default transformation\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 128, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('/home/ubuntu/Documents/ELA/models/prsz_299_freezed_ela_iter22')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_128_frz_set0')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_128_unfrz_set0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:16 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.513156</th>\n",
       "    <th>0.507871</th>\n",
       "    <th>0.759143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.518863</th>\n",
       "    <th>0.507453</th>\n",
       "    <th>0.758857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.517992</th>\n",
       "    <th>0.505678</th>\n",
       "    <th>0.758857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.502330</th>\n",
       "    <th>0.505530</th>\n",
       "    <th>0.759714</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:30 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.503629</th>\n",
       "    <th>0.503987</th>\n",
       "    <th>0.757714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.500678</th>\n",
       "    <th>0.503320</th>\n",
       "    <th>0.755429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:31 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.495593</th>\n",
       "    <th>0.504584</th>\n",
       "    <th>0.757429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.496892</th>\n",
       "    <th>0.503236</th>\n",
       "    <th>0.760286</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2nd iter model on size 128\n",
    "files, labels = train_files_all[1], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 128, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_128_unfrz_set0')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_128_frz_set1')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_128_unfrz_set1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:16 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.501382</th>\n",
       "    <th>0.503782</th>\n",
       "    <th>0.759143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.497225</th>\n",
       "    <th>0.500694</th>\n",
       "    <th>0.759714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.489146</th>\n",
       "    <th>0.501273</th>\n",
       "    <th>0.756857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.488903</th>\n",
       "    <th>0.501094</th>\n",
       "    <th>0.759143</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:31 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.498618</th>\n",
       "    <th>0.499787</th>\n",
       "    <th>0.760571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.487119</th>\n",
       "    <th>0.500565</th>\n",
       "    <th>0.762000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:30 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.475199</th>\n",
       "    <th>0.503268</th>\n",
       "    <th>0.762286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.481139</th>\n",
       "    <th>0.502274</th>\n",
       "    <th>0.764000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3rd iter model on size 128\n",
    "files, labels = train_files_all[2], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 128, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_128_unfrz_set1')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_128_frz_set2')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_128_unfrz_set2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:36 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.485350</th>\n",
       "    <th>0.524085</th>\n",
       "    <th>0.754000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.484521</th>\n",
       "    <th>0.503620</th>\n",
       "    <th>0.754000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.480798</th>\n",
       "    <th>0.502310</th>\n",
       "    <th>0.764857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.469499</th>\n",
       "    <th>0.494159</th>\n",
       "    <th>0.769429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:54 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.465912</th>\n",
       "    <th>0.495280</th>\n",
       "    <th>0.766286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.466468</th>\n",
       "    <th>0.488342</th>\n",
       "    <th>0.773429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.464466</th>\n",
       "    <th>0.502645</th>\n",
       "    <th>0.762286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.468186</th>\n",
       "    <th>0.498425</th>\n",
       "    <th>0.765143</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1st iter model on size 224\n",
    "files, labels = train_files_all[0], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 224, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_128_unfrz_set2')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_224_frz_set0')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_224_unfrz_set0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:33 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.478043</th>\n",
       "    <th>0.492816</th>\n",
       "    <th>0.758286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.480025</th>\n",
       "    <th>0.497928</th>\n",
       "    <th>0.753143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.469031</th>\n",
       "    <th>0.486419</th>\n",
       "    <th>0.760571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.460763</th>\n",
       "    <th>0.497334</th>\n",
       "    <th>0.752286</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.476757</th>\n",
       "    <th>0.488769</th>\n",
       "    <th>0.760286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.458073</th>\n",
       "    <th>0.489804</th>\n",
       "    <th>0.761143</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.461036</th>\n",
       "    <th>0.490110</th>\n",
       "    <th>0.758571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.459241</th>\n",
       "    <th>0.482985</th>\n",
       "    <th>0.764571</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2nd iter model on size 224\n",
    "files, labels = train_files_all[1], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 224, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_224_unfrz_set0')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_224_frz_set1')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_224_unfrz_set1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:33 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.458445</th>\n",
       "    <th>0.495060</th>\n",
       "    <th>0.770857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.457484</th>\n",
       "    <th>0.482811</th>\n",
       "    <th>0.770571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.451893</th>\n",
       "    <th>0.500084</th>\n",
       "    <th>0.760857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.448551</th>\n",
       "    <th>0.487775</th>\n",
       "    <th>0.769429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.463320</th>\n",
       "    <th>0.483189</th>\n",
       "    <th>0.773714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.444985</th>\n",
       "    <th>0.482079</th>\n",
       "    <th>0.771429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 03:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.448058</th>\n",
       "    <th>0.480700</th>\n",
       "    <th>0.772857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.445798</th>\n",
       "    <th>0.483240</th>\n",
       "    <th>0.771143</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3rd iter model on size 224\n",
    "files, labels = train_files_all[2], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 224, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_224_unfrz_set1')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_224_frz_set2')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_224_unfrz_set2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:39 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.456077</th>\n",
       "    <th>0.469530</th>\n",
       "    <th>0.782571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.460838</th>\n",
       "    <th>0.467895</th>\n",
       "    <th>0.782857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.459286</th>\n",
       "    <th>0.464442</th>\n",
       "    <th>0.785143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.442363</th>\n",
       "    <th>0.465460</th>\n",
       "    <th>0.783429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:09 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.460074</th>\n",
       "    <th>0.470524</th>\n",
       "    <th>0.780286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.448075</th>\n",
       "    <th>0.467222</th>\n",
       "    <th>0.783429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:07 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.424523</th>\n",
       "    <th>0.465925</th>\n",
       "    <th>0.785429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.439334</th>\n",
       "    <th>0.467333</th>\n",
       "    <th>0.784571</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1st iter model on size 299\n",
    "files, labels = train_files_all[0], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 299, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_224_unfrz_set2')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_299_frz_set0')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_299_unfrz_set0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:33 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.454746</th>\n",
       "    <th>0.471391</th>\n",
       "    <th>0.775143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.442271</th>\n",
       "    <th>0.470967</th>\n",
       "    <th>0.778857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.441257</th>\n",
       "    <th>0.470947</th>\n",
       "    <th>0.778286</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.439012</th>\n",
       "    <th>0.471762</th>\n",
       "    <th>0.780857</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:08 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.452828</th>\n",
       "    <th>0.487525</th>\n",
       "    <th>0.765429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.426538</th>\n",
       "    <th>0.473686</th>\n",
       "    <th>0.777143</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:07 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.431918</th>\n",
       "    <th>0.478344</th>\n",
       "    <th>0.776571</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.417714</th>\n",
       "    <th>0.476806</th>\n",
       "    <th>0.777429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2nd iter model on size 299\n",
    "files, labels = train_files_all[1], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 299, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_299_unfrz_set0')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_299_frz_set1')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_299_unfrz_set1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:34 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.430627</th>\n",
       "    <th>0.480224</th>\n",
       "    <th>0.775429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.440238</th>\n",
       "    <th>0.477205</th>\n",
       "    <th>0.778857</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.430465</th>\n",
       "    <th>0.478991</th>\n",
       "    <th>0.779714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.425552</th>\n",
       "    <th>0.477765</th>\n",
       "    <th>0.778857</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:08 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.436265</th>\n",
       "    <th>0.476740</th>\n",
       "    <th>0.781143</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.415353</th>\n",
       "    <th>0.475092</th>\n",
       "    <th>0.782000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 07:08 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.407751</th>\n",
       "    <th>0.475758</th>\n",
       "    <th>0.777714</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.406571</th>\n",
       "    <th>0.476755</th>\n",
       "    <th>0.779429</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f26c8dd57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    }
   ],
   "source": [
    "# 3rd iter model on size 299\n",
    "files, labels = train_files_all[2], train_label\n",
    "path = 'home/ubuntu/Documents/ELA2/'\n",
    "fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 299, test = 'test', bs = 64, ds_tfms = tfms)\n",
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('ela2_prsz_299_unfrz_set1')\n",
    "learn.fit_one_cycle(4)\n",
    "learn.save('ela2_prsz_299_frz_set2')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))\n",
    "learn.fit_one_cycle(2, max_lr = slice(5e-6,1e-5))\n",
    "learn.save('ela2_prsz_299_unfrz_set2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_data.py:211: UserWarning: Your training dataloader is empty, you have only 43 items in your training set.\n",
      "                 Your batch size is 64, you should lower it.\n",
      "  Your batch size is {self.train_dl.batch_size}, you should lower it.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Test on the holdout validation set.\n",
    "fname2label = {f:l for (f,l) in zip(val_files, val_label)}\n",
    "src = ImageItemList(val_files, path=path).random_split_by_pct(valid_pct=0.99, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "tfms = get_transforms()\n",
    "tfms = (tfms[0][1:],[])\n",
    "data = ImageDataBunch.create_from_ll(src, size = 299, bs = 64, ds_tfms = tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (43 items)\n",
       "[Category real, Category real, Category real, Category real, Category real]...\n",
       "Path: /home/ubuntu/Documents/ELA\n",
       "x: ImageItemList (43 items)\n",
       "[Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224)]...\n",
       "Path: /home/ubuntu/Documents/ELA;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (4217 items)\n",
       "[Category fake, Category fake, Category fake, Category fake, Category fake]...\n",
       "Path: /home/ubuntu/Documents/ELA\n",
       "x: ImageItemList (4217 items)\n",
       "[Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224), Image (3, 224, 224)]...\n",
       "Path: /home/ubuntu/Documents/ELA;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f26efb12b70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ubuntu/Documents/ELA'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace)\n",
       "  (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU(inplace)\n",
       "  (22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (28): ReLU(inplace)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): ReLU(inplace)\n",
       "  (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "), Sequential(\n",
       "  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU(inplace)\n",
       "  (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): ReLU(inplace)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): ReLU(inplace)\n",
       "  (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (37): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): ReLU(inplace)\n",
       "  (42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): ReLU(inplace)\n",
       "  (47): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Flatten()\n",
       "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "learn.load('/home/ubuntu/home/ubuntu/Documents/ELA2/models/ela2_prsz_299_unfrz_set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2858, 1359]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(learn.data.valid_ds.y.items, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7638183946703178\n",
      "Accuracy:  0.7562248043632914\n",
      "[[2063  795]\n",
      " [ 233 1126]]\n"
     ]
    }
   ],
   "source": [
    "temp = np.argmax(p[0], axis = 1)\n",
    "get_metrics(data.valid_ds.y.items, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_ela_1(modelname):\n",
    "    fname2label = {f:l for (f,l) in zip(val_files, val_label)}\n",
    "    path = '/home/ubuntu/Documents/ELA/'\n",
    "    src = ImageItemList(val_files, path=path).random_split_by_pct(valid_pct=0.99, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "    tfms = get_transforms()\n",
    "    tfms = (tfms[0][1:],[])\n",
    "    data = ImageDataBunch.create_from_ll(src, size = 299, bs = 64, test = 'test', ds_tfms = tfms)\n",
    "    learn = create_cnn(data, resnet34, pretrained=True, metrics = accuracy)\n",
    "    learn.load(f'/home/ubuntu/home/ubuntu/Documents/ELA2/models/{modelname}')\n",
    "    print(np.unique(learn.data.valid_ds.y.items, return_counts = True))\n",
    "    learn.data.test_dl.items.sort()\n",
    "    print(len(learn.data.test_ds.items))\n",
    "    print(learn.data.test_dl.x.items[8])\n",
    "    return learn\n",
    "\n",
    "def get_normal_data(modelname):\n",
    "    path = '/home/ubuntu/share/stage-3/stage3_image_data/'\n",
    "    val_files_1 = ['/home/ubuntu/share/stage-3/stage3_image_data/' + '/'.join(x.split('/')[-3:]) for x in val_files]\n",
    "    fname2label = {f:l for (f,l) in zip(val_files_1, val_label)}\n",
    "    src = ImageItemList(val_files_1, path=path).random_split_by_pct(valid_pct=0.99, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "    tfms = get_transforms()\n",
    "    tfms = (tfms[0][1:],[])\n",
    "    data = ImageDataBunch.create_from_ll(src, size = 224, bs = 64, ds_tfms = tfms, test = 'test')\n",
    "    data.path = '/home/ubuntu/Documents/'\n",
    "    learn = create_cnn(data, resnet50, pretrained=True, metrics = accuracy)\n",
    "    print(np.unique(learn.data.valid_ds.y.items, return_counts = True))\n",
    "    learn.data.test_dl.items.sort()\n",
    "    print(len(learn.data.test_ds.items))\n",
    "    print(learn.data.test_dl.x.items[8])\n",
    "    learn.load(f'/home/ubuntu/Documents/models/{modelname}')\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = {'resnet18': models.resnet18, 'resnet34': models.resnet34, 'resnet50': models.resnet50, 'resnet101': models.resnet101}\n",
    "models_used_def = ['ela2_prsz_299_unfrz_set2','resnet50_trns_iter_2']\n",
    "def get_ensemble(models_used = models_used_def, is_test = False):\n",
    "    models_combined = pd.DataFrame()\n",
    "    all_res = {}\n",
    "    for i in models_used:\n",
    "        print(i)\n",
    "        netname = i.split('_')[0]\n",
    "#         arch = net_dict[netname]\n",
    "        if('ela' in i):\n",
    "            # need to load data from ela folder\n",
    "            learn = get_data_for_ela_1(i)\n",
    "        else:\n",
    "            learn = get_normal_data(i)\n",
    "        if(is_test):\n",
    "            d = DatasetType.Test\n",
    "        else:\n",
    "            d = DatasetType.Valid\n",
    "        probs = learn.get_preds(d)\n",
    "        all_res[i] = np.argmax(probs[0], axis = 1)\n",
    "        all_res[i+'fake'] = [float(x[0]) for x in probs[0]]\n",
    "        all_res[i+'real'] = [float(x[1]) for x in probs[0]]\n",
    "        if(is_test == False):\n",
    "            get_metrics(data.valid_ds.y.items, all_res[i])\n",
    "        all_res[i+'|prob'] = np.max(np.array(probs[0]), axis = 1)\n",
    "    models_combined = pd.DataFrame(all_res)\n",
    "    return models_combined\n",
    "\n",
    "def get_ensemble_submission(is_t = False):\n",
    "    results_combined = get_ensemble(is_test = is_t)\n",
    "    results_combined['confident'] = results_combined[[x+'|prob' for x in models_used_def]].idxmax(axis = 1)\n",
    "    results_combined['label'] = results_combined.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)\n",
    "    return results_combined['label'].astype(int).values\n",
    "\n",
    "def get_submission_file(learn, ensemble = True, output_filename = 'final_submission.csv'):\n",
    "    if(ensemble):\n",
    "        test_preds = get_ensemble_submission(True)\n",
    "    else:\n",
    "        test_predictions = learn.predict(is_test = True)\n",
    "        test_preds = np.argmax(test_predictions, axis=1)  # from log probabilities to 0 or 1ts\n",
    "        test_probs = np.exp(test_predictions[:,1])        # pr()\n",
    "        \n",
    "    labels = [data.classes[x] for x in test_preds]\n",
    "    assert(len(data.test_dl.x.items) == len(labels))\n",
    "    \n",
    "    output_df = pd.DataFrame({'Filename':data.test_dl.x.items, 'Prediction': np.array(labels)})\n",
    "    output_df['Filename'] = output_df['Filename'].apply(lambda x: str(x).split('/')[-1])\n",
    "    \n",
    "    output_df.to_csv(output_filename, index=False)\n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dela = get_data_for_ela_1()\n",
    "# len(dela.test_ds.y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7572649556377495\n",
      "Accuracy:  0.7491107422338155\n",
      "[[1993  865]\n",
      " [ 193 1166]]\n"
     ]
    }
   ],
   "source": [
    "comb = get_ensemble(is_test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['confident'] = comb[[x+'|prob' for x in models_used_def]].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['label'] = comb.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.8205281496603728\n",
      "Accuracy:  0.8152715200379417\n",
      "[[2241  617]\n",
      " [ 162 1197]]\n"
     ]
    }
   ],
   "source": [
    "# Ensemble result on holdout val set\n",
    "get_metrics(data.valid_ds.y.items, comb.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = get_ensemble(is_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['confident'] = comb[[x+'|prob' for x in models_used_def]].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['label'] = comb.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ela2_prsz_299_unfrz_set2</th>\n",
       "      <th>ela2_prsz_299_unfrz_set2fake</th>\n",
       "      <th>ela2_prsz_299_unfrz_set2real</th>\n",
       "      <th>ela2_prsz_299_unfrz_set2|prob</th>\n",
       "      <th>resnet50_trns_iter_2</th>\n",
       "      <th>resnet50_trns_iter_2fake</th>\n",
       "      <th>resnet50_trns_iter_2real</th>\n",
       "      <th>resnet50_trns_iter_2|prob</th>\n",
       "      <th>confident</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.294935</td>\n",
       "      <td>0.705065</td>\n",
       "      <td>0.705065</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410452</td>\n",
       "      <td>0.589548</td>\n",
       "      <td>0.589548</td>\n",
       "      <td>ela2_prsz_299_unfrz_set2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.883732</td>\n",
       "      <td>0.116267</td>\n",
       "      <td>0.883732</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510377</td>\n",
       "      <td>0.489623</td>\n",
       "      <td>0.510377</td>\n",
       "      <td>ela2_prsz_299_unfrz_set2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.973347</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>0.973347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934513</td>\n",
       "      <td>0.065487</td>\n",
       "      <td>0.934513</td>\n",
       "      <td>ela2_prsz_299_unfrz_set2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.585824</td>\n",
       "      <td>0.414176</td>\n",
       "      <td>0.585824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826101</td>\n",
       "      <td>0.173899</td>\n",
       "      <td>0.826101</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.548104</td>\n",
       "      <td>0.548104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ela2_prsz_299_unfrz_set2  ela2_prsz_299_unfrz_set2fake  \\\n",
       "0                         1                      0.294935   \n",
       "1                         0                      0.883732   \n",
       "2                         0                      0.973347   \n",
       "3                         0                      0.585824   \n",
       "4                         1                      0.451896   \n",
       "\n",
       "   ela2_prsz_299_unfrz_set2real  ela2_prsz_299_unfrz_set2|prob  \\\n",
       "0                      0.705065                       0.705065   \n",
       "1                      0.116267                       0.883732   \n",
       "2                      0.026653                       0.973347   \n",
       "3                      0.414176                       0.585824   \n",
       "4                      0.548104                       0.548104   \n",
       "\n",
       "   resnet50_trns_iter_2  resnet50_trns_iter_2fake  resnet50_trns_iter_2real  \\\n",
       "0                     1                  0.410452                  0.589548   \n",
       "1                     0                  0.510377                  0.489623   \n",
       "2                     0                  0.934513                  0.065487   \n",
       "3                     0                  0.826101                  0.173899   \n",
       "4                     1                  0.145631                  0.854369   \n",
       "\n",
       "   resnet50_trns_iter_2|prob                      confident  label  \n",
       "0                   0.589548  ela2_prsz_299_unfrz_set2|prob      1  \n",
       "1                   0.510377  ela2_prsz_299_unfrz_set2|prob      0  \n",
       "2                   0.934513  ela2_prsz_299_unfrz_set2|prob      0  \n",
       "3                   0.826101      resnet50_trns_iter_2|prob      0  \n",
       "4                   0.854369      resnet50_trns_iter_2|prob      1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = comb['label'].astype(int).values\n",
    "lals = [data.classes[x] for x in la]\n",
    "assert(len(data.test_dl.x.items) == len(lals))\n",
    "\n",
    "output_df = pd.DataFrame({'Filename':data.test_dl.x.items, 'Prediction': np.array(lals)})\n",
    "output_df['Filename'] = output_df['Filename'].apply(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "output_df.to_csv('submission_ensemble_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    2752\n",
       "fake    2678\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.Prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resnet50_trns_iter_2</th>\n",
       "      <th>resnet50_trns_iter_2fake</th>\n",
       "      <th>resnet50_trns_iter_2real</th>\n",
       "      <th>resnet50_trns_iter_2|prob</th>\n",
       "      <th>resnet34_ela_299_iter22</th>\n",
       "      <th>resnet34_ela_299_iter22fake</th>\n",
       "      <th>resnet34_ela_299_iter22real</th>\n",
       "      <th>resnet34_ela_299_iter22|prob</th>\n",
       "      <th>confident</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416043</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206869</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318592</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322339</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>0.343088</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429506</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.246356</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resnet50_trns_iter_2  resnet50_trns_iter_2fake  resnet50_trns_iter_2real  \\\n",
       "0                     1                  0.055228                  0.944772   \n",
       "1                     1                  0.206869                  0.793131   \n",
       "2                     1                  0.318592                  0.681408   \n",
       "3                     0                  0.656912                  0.343088   \n",
       "4                     0                  0.753644                  0.246356   \n",
       "\n",
       "   resnet50_trns_iter_2|prob  resnet34_ela_299_iter22  \\\n",
       "0                   0.944772                        1   \n",
       "1                   0.793131                        1   \n",
       "2                   0.681408                        1   \n",
       "3                   0.656912                        1   \n",
       "4                   0.753644                        1   \n",
       "\n",
       "   resnet34_ela_299_iter22fake  resnet34_ela_299_iter22real  \\\n",
       "0                     0.416043                     0.583957   \n",
       "1                     0.497745                     0.502255   \n",
       "2                     0.322339                     0.677661   \n",
       "3                     0.429506                     0.570494   \n",
       "4                     0.450236                     0.549764   \n",
       "\n",
       "   resnet34_ela_299_iter22|prob                  confident  label  \n",
       "0                      0.583957  resnet50_trns_iter_2|prob      1  \n",
       "1                      0.502255  resnet50_trns_iter_2|prob      1  \n",
       "2                      0.677661  resnet50_trns_iter_2|prob      1  \n",
       "3                      0.570494  resnet50_trns_iter_2|prob      0  \n",
       "4                      0.549764  resnet50_trns_iter_2|prob      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough, no need to refer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = create_cnn(data, models.resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 37:04 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.710183</th>\n",
       "    <th>0.618685</th>\n",
       "    <th>0.656235</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.622221</th>\n",
       "    <th>0.594685</th>\n",
       "    <th>0.688485</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.578733</th>\n",
       "    <th>0.576262</th>\n",
       "    <th>0.695891</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.548707</th>\n",
       "    <th>0.567682</th>\n",
       "    <th>0.709986</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet50_trns_iter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 18:43 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.548446</th>\n",
       "    <th>0.555912</th>\n",
       "    <th>0.711897</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.484806</th>\n",
       "    <th>0.546715</th>\n",
       "    <th>0.725036</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet50_trns_iter_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 19:38 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.448832</th>\n",
       "    <th>0.555732</th>\n",
       "    <th>0.726708</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.372659</th>\n",
       "    <th>0.561016</th>\n",
       "    <th>0.736742</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, max_lr = slice(1e-5,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet50_trns_iter_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake', 'real']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.classes)\n",
    "learn.data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 58:48 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.560081</th>\n",
       "    <th>0.587431</th>\n",
       "    <th>0.688247</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.585592</th>\n",
       "    <th>0.583629</th>\n",
       "    <th>0.691352</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.548207</th>\n",
       "    <th>0.576736</th>\n",
       "    <th>0.699952</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.526985</th>\n",
       "    <th>0.575528</th>\n",
       "    <th>0.705208</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.544158</th>\n",
       "    <th>0.572644</th>\n",
       "    <th>0.703058</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, max_lr = slice(1e-5,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (12560 items)\n",
       "[Category real, Category real, Category real, Category real, Category real]...\n",
       "Path: /home/ubuntu/share/stage-3/stage3_image_data\n",
       "x: ImageItemList (12560 items)\n",
       "[Image (3, 717, 960), Image (3, 720, 1280), Image (3, 900, 600), Image (3, 750, 499), Image (3, 750, 499)]...\n",
       "Path: /home/ubuntu/share/stage-3/stage3_image_data;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (4186 items)\n",
       "[Category real, Category real, Category real, Category real, Category fake]...\n",
       "Path: /home/ubuntu/share/stage-3/stage3_image_data\n",
       "x: ImageItemList (4186 items)\n",
       "[Image (3, 1024, 729), Image (3, 600, 600), Image (3, 2246, 3369), Image (3, 1026, 900), Image (3, 1200, 1600)]...\n",
       "Path: /home/ubuntu/share/stage-3/stage3_image_data;\n",
       "\n",
       "Test: LabelList\n",
       "y: EmptyLabelList (5430 items)\n",
       "[EmptyLabel , EmptyLabel , EmptyLabel , EmptyLabel , EmptyLabel ]...\n",
       "Path: .\n",
       "x: ImageItemList (5430 items)\n",
       "[Image (3, 714, 964), Image (3, 1125, 1500), Image (3, 660, 970), Image (3, 1080, 1920), Image (3, 720, 537)]...\n",
       "Path: /home/ubuntu/share/stage-3/stage3_image_data, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fd074547b70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ubuntu/Documents'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace)\n",
       "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace)\n",
       "  (27): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): ReLU(inplace)\n",
       "  (43): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (44): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (45): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (46): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): ReLU(inplace)\n",
       "  (50): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (51): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (52): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): ReLU(inplace)\n",
       "  (37): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (42): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (43): ReLU(inplace)\n",
       "  (44): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (48): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (50): ReLU(inplace)\n",
       "  (51): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (52): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (53): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (55): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (56): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (57): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): ReLU(inplace)\n",
       "  (60): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (62): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (64): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Flatten()\n",
       "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = ImageDataBunch.create_from_ll(src, size = 224, test = 'test', bs = 32, ds_tfms = get_transforms())\n",
    "# data.path = '/home/ubuntu/Documents/'\n",
    "learn = create_cnn(data, models.resnet50, metrics=accuracy)\n",
    "learn.load('resnet50_trns_iter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2393, 0.7607],\n",
       "         [0.1080, 0.8920],\n",
       "         [0.2749, 0.7251],\n",
       "         ...,\n",
       "         [0.3568, 0.6432],\n",
       "         [0.2401, 0.7599],\n",
       "         [0.6485, 0.3515]]), tensor([1, 1, 1,  ..., 0, 1, 0])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = learn.get_preds()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [float(x[1]) for x in l[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.argmax(l[0], axis = 1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 798, 3388]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(temp, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.474204842480635\n",
      "Accuracy:  0.524605828953655\n",
      "[[ 445 1637]\n",
      " [ 353 1751]]\n"
     ]
    }
   ],
   "source": [
    "get_metrics(data.valid_ds.y.items, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0702, 0.9298],\n",
       "         [0.2291, 0.7709],\n",
       "         [0.2932, 0.7068],\n",
       "         ...,\n",
       "         [0.5602, 0.4398],\n",
       "         [0.2433, 0.7567],\n",
       "         [0.3969, 0.6031]]), tensor([0, 0, 0,  ..., 0, 0, 0])]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting test predictions\n",
    "test_output = learn.get_preds(DatasetType.Test)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, ..., 1, 0, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmax(test_output[0], axis = 1)\n",
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'Filename':data.test_dl.x.items, 'Prediction': np.array(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['Filename'] = output_df['Filename'].apply(lambda x: str(x).split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a7458a237d5d457c88ff8ebacb73481.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63b3f3fd3a255d3ff49ad52ac7f34453.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65093b60262226d52221d4fa17f614cc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ee7256d99e720cbb653b6a536871307.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e20d2f9863e74bbd0fdbc4c3e38f092b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Filename  Prediction\n",
       "0  3a7458a237d5d457c88ff8ebacb73481.jpg           1\n",
       "1  63b3f3fd3a255d3ff49ad52ac7f34453.jpg           1\n",
       "2  65093b60262226d52221d4fa17f614cc.jpg           1\n",
       "3  9ee7256d99e720cbb653b6a536871307.jpg           1\n",
       "4  e20d2f9863e74bbd0fdbc4c3e38f092b.jpg           1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['Prediction'] = output_df['Prediction'].map({0: 'fake', 1: 'real'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a7458a237d5d457c88ff8ebacb73481.jpg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63b3f3fd3a255d3ff49ad52ac7f34453.jpg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65093b60262226d52221d4fa17f614cc.jpg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ee7256d99e720cbb653b6a536871307.jpg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e20d2f9863e74bbd0fdbc4c3e38f092b.jpg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Filename Prediction\n",
       "0  3a7458a237d5d457c88ff8ebacb73481.jpg       real\n",
       "1  63b3f3fd3a255d3ff49ad52ac7f34453.jpg       real\n",
       "2  65093b60262226d52221d4fa17f614cc.jpg       real\n",
       "3  9ee7256d99e720cbb653b6a536871307.jpg       real\n",
       "4  e20d2f9863e74bbd0fdbc4c3e38f092b.jpg       real"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    4709\n",
       "fake     721\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('submission_only_resnet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0702, 0.9298],\n",
       "        [0.2291, 0.7709],\n",
       "        [0.2932, 0.7068],\n",
       "        ...,\n",
       "        [0.5602, 0.4398],\n",
       "        [0.2433, 0.7567],\n",
       "        [0.3969, 0.6031]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, ..., 1, 0, 1, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(test_output[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_ela():\n",
    "    path = '/home/ubuntu/Documents/ELA'\n",
    "    files_df = pd.read_csv('training_data.csv')\n",
    "    files,labels = list(files_df['Files'].values), list(files_df['labels'].values)\n",
    "    \n",
    "    files = ['/home/ubuntu/Documents/ELA/' + '/'.join(x.split('/')[-3:]) for x in files]\n",
    "    fname2label = {f:l for (f,l) in zip(files, labels)}\n",
    "    src = ImageItemList(files, path=path).random_split_by_pct(valid_pct=0.25, seed=42).label_from_func(lambda x:fname2label[x])\n",
    "    \n",
    "    data = ImageDataBunch.create_from_ll(src, size = 299, test = 'test', bs = 32, ds_tfms = None)\n",
    "    data.path = '/home/ubuntu/Documents/'\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = {'resnet18': models.resnet18, 'resnet34': models.resnet34, 'resnet50': models.resnet50, 'resnet101': models.resnet101}\n",
    "models_used_def = ['resnet50_trns_iter_2','resnet34_ela_299_iter22']\n",
    "def get_ensemble(models_used = models_used_def, is_test = False):\n",
    "    models_combined = pd.DataFrame()\n",
    "    all_res = {}\n",
    "    for i in models_used:\n",
    "        print(i)\n",
    "        netname = i.split('_')[0]\n",
    "        arch = net_dict[netname]\n",
    "        if('ela' in i):\n",
    "            # need to load data from ela folder\n",
    "            print('its ela')\n",
    "            data_ela = get_data_for_ela()\n",
    "            learn = create_cnn(data_ela, arch, metrics=accuracy)\n",
    "            learn.load(i)\n",
    "        else:\n",
    "            learn = create_cnn(data, arch, metrics=accuracy)\n",
    "            learn.load(i)\n",
    "        if(is_test):\n",
    "            d = DatasetType.Test\n",
    "        else:\n",
    "            d = DatasetType.Valid\n",
    "        probs = learn.get_preds(d)\n",
    "        all_res[i] = np.argmax(probs[0], axis = 1)\n",
    "        all_res[i+'fake'] = [float(x[0]) for x in probs[0]]\n",
    "        all_res[i+'real'] = [float(x[1]) for x in probs[0]]\n",
    "        if(is_test == False):\n",
    "            get_metrics(data.valid_ds.y.items, all_res[i])\n",
    "        all_res[i+'|prob'] = np.max(np.array(probs[0]), axis = 1)\n",
    "    models_combined = pd.DataFrame(all_res)\n",
    "    return models_combined\n",
    "\n",
    "def get_ensemble_submission(is_t = False):\n",
    "    results_combined = get_ensemble(is_test = is_t)\n",
    "    results_combined['confident'] = results_combined[[x+'|prob' for x in models_used_def]].idxmax(axis = 1)\n",
    "    results_combined['label'] = results_combined.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)\n",
    "    return results_combined['label'].astype(int).values\n",
    "\n",
    "def get_submission_file(learn, ensemble = True, output_filename = 'final_submission.csv'):\n",
    "    if(ensemble):\n",
    "        test_preds = get_ensemble_submission(True)\n",
    "    else:\n",
    "        test_predictions = learn.predict(is_test = True)\n",
    "        test_preds = np.argmax(test_predictions, axis=1)  # from log probabilities to 0 or 1ts\n",
    "        test_probs = np.exp(test_predictions[:,1])        # pr()\n",
    "        \n",
    "    labels = [data.classes[x] for x in test_preds]\n",
    "    assert(len(data.test_dl.x.items) == len(labels))\n",
    "    \n",
    "    output_df = pd.DataFrame({'Filename':data.test_dl.x.items, 'Prediction': np.array(labels)})\n",
    "    output_df['Filename'] = output_df['Filename'].apply(lambda x: str(x).split('/')[-1])\n",
    "    \n",
    "    output_df.to_csv(output_filename, index=False)\n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dela = get_data_for_ela()\n",
    "len(dela.test_ds.y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7995151962610598\n",
      "Accuracy:  0.8000477783086479\n",
      "[[1561  521]\n",
      " [ 316 1788]]\n"
     ]
    }
   ],
   "source": [
    "comb = get_ensemble(is_test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = get_ensemble(is_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['confident'] = comb[[x+'|prob' for x in models_used_def]].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['label'] = comb.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = comb['label'].astype(int).values\n",
    "lals = [data.classes[x] for x in la]\n",
    "assert(len(data.test_dl.x.items) == len(lals))\n",
    "\n",
    "output_df = pd.DataFrame({'Filename':data.test_dl.x.items, 'Prediction': np.array(lals)})\n",
    "output_df['Filename'] = output_df['Filename'].apply(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "output_df.to_csv('submission_ela_ens', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    2800\n",
       "fake    2630\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.Prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resnet50_trns_iter_2</th>\n",
       "      <th>resnet50_trns_iter_2fake</th>\n",
       "      <th>resnet50_trns_iter_2real</th>\n",
       "      <th>resnet50_trns_iter_2|prob</th>\n",
       "      <th>resnet34_ela_299_iter22</th>\n",
       "      <th>resnet34_ela_299_iter22fake</th>\n",
       "      <th>resnet34_ela_299_iter22real</th>\n",
       "      <th>resnet34_ela_299_iter22|prob</th>\n",
       "      <th>confident</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416043</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206869</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318592</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322339</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>0.343088</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429506</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.246356</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resnet50_trns_iter_2  resnet50_trns_iter_2fake  resnet50_trns_iter_2real  \\\n",
       "0                     1                  0.055228                  0.944772   \n",
       "1                     1                  0.206869                  0.793131   \n",
       "2                     1                  0.318592                  0.681408   \n",
       "3                     0                  0.656912                  0.343088   \n",
       "4                     0                  0.753644                  0.246356   \n",
       "\n",
       "   resnet50_trns_iter_2|prob  resnet34_ela_299_iter22  \\\n",
       "0                   0.944772                        1   \n",
       "1                   0.793131                        1   \n",
       "2                   0.681408                        1   \n",
       "3                   0.656912                        1   \n",
       "4                   0.753644                        1   \n",
       "\n",
       "   resnet34_ela_299_iter22fake  resnet34_ela_299_iter22real  \\\n",
       "0                     0.416043                     0.583957   \n",
       "1                     0.497745                     0.502255   \n",
       "2                     0.322339                     0.677661   \n",
       "3                     0.429506                     0.570494   \n",
       "4                     0.450236                     0.549764   \n",
       "\n",
       "   resnet34_ela_299_iter22|prob                  confident  label  \n",
       "0                      0.583957  resnet50_trns_iter_2|prob      1  \n",
       "1                      0.502255  resnet50_trns_iter_2|prob      1  \n",
       "2                      0.677661  resnet50_trns_iter_2|prob      1  \n",
       "3                      0.570494  resnet50_trns_iter_2|prob      0  \n",
       "4                      0.549764  resnet50_trns_iter_2|prob      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.8282291803995502\n",
      "Accuracy:  0.8284758719541329\n",
      "[[1649  433]\n",
      " [ 285 1819]]\n"
     ]
    }
   ],
   "source": [
    "get_metrics(data.valid_ds.y.items, comb.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb['average_fake'] = (comb['resnet50_trns_iter_2fake'] + comb['resnet34_ela_299_iter22fake']) / 2.0\n",
    "comb['average_real'] = (comb['resnet50_trns_iter_2real'] + comb['resnet34_ela_299_iter22real']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resnet50_trns_iter_2</th>\n",
       "      <th>resnet50_trns_iter_2fake</th>\n",
       "      <th>resnet50_trns_iter_2real</th>\n",
       "      <th>resnet50_trns_iter_2|prob</th>\n",
       "      <th>resnet34_ela_299_iter22</th>\n",
       "      <th>resnet34_ela_299_iter22fake</th>\n",
       "      <th>resnet34_ela_299_iter22real</th>\n",
       "      <th>resnet34_ela_299_iter22|prob</th>\n",
       "      <th>confident</th>\n",
       "      <th>label</th>\n",
       "      <th>average_fake</th>\n",
       "      <th>average_real</th>\n",
       "      <th>label_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>0.944772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416043</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235636</td>\n",
       "      <td>0.764364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206869</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352307</td>\n",
       "      <td>0.647693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318592</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322339</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>0.677661</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320466</td>\n",
       "      <td>0.679534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>0.343088</td>\n",
       "      <td>0.656912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429506</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>0.570494</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543209</td>\n",
       "      <td>0.456791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.246356</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>0.549764</td>\n",
       "      <td>resnet50_trns_iter_2|prob</td>\n",
       "      <td>0</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>0.398060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resnet50_trns_iter_2  resnet50_trns_iter_2fake  resnet50_trns_iter_2real  \\\n",
       "0                     1                  0.055228                  0.944772   \n",
       "1                     1                  0.206869                  0.793131   \n",
       "2                     1                  0.318592                  0.681408   \n",
       "3                     0                  0.656912                  0.343088   \n",
       "4                     0                  0.753644                  0.246356   \n",
       "\n",
       "   resnet50_trns_iter_2|prob  resnet34_ela_299_iter22  \\\n",
       "0                   0.944772                        1   \n",
       "1                   0.793131                        1   \n",
       "2                   0.681408                        1   \n",
       "3                   0.656912                        1   \n",
       "4                   0.753644                        1   \n",
       "\n",
       "   resnet34_ela_299_iter22fake  resnet34_ela_299_iter22real  \\\n",
       "0                     0.416043                     0.583957   \n",
       "1                     0.497745                     0.502255   \n",
       "2                     0.322339                     0.677661   \n",
       "3                     0.429506                     0.570494   \n",
       "4                     0.450236                     0.549764   \n",
       "\n",
       "   resnet34_ela_299_iter22|prob                  confident  label  \\\n",
       "0                      0.583957  resnet50_trns_iter_2|prob      1   \n",
       "1                      0.502255  resnet50_trns_iter_2|prob      1   \n",
       "2                      0.677661  resnet50_trns_iter_2|prob      1   \n",
       "3                      0.570494  resnet50_trns_iter_2|prob      0   \n",
       "4                      0.549764  resnet50_trns_iter_2|prob      0   \n",
       "\n",
       "   average_fake  average_real  label_avg  \n",
       "0      0.235636      0.764364          1  \n",
       "1      0.352307      0.647693          1  \n",
       "2      0.320466      0.679534          1  \n",
       "3      0.543209      0.456791          0  \n",
       "4      0.601940      0.398060          0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.8282291803995502\n",
      "Accuracy:  0.8284758719541329\n",
      "[[1649  433]\n",
      " [ 285 1819]]\n"
     ]
    }
   ],
   "source": [
    "comb['label_avg'] = comb[['average_fake','average_real']].idxmax(axis = 1)\n",
    "comb['label_avg'] = comb['label_avg'].map({'average_fake':0, 'average_real':1})\n",
    "get_metrics(data.valid_ds.y.items, comb.label_avg.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.to_csv('first_cut_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_combined['confident'] = model_combined[[x+'|prob' for x in models_used_i]].idxmax(axis = 1)\n",
    "\n",
    "boo = model_combined[models_used_i].mode(axis=1)\n",
    "boonull = boo.isnull()\n",
    "for i,row in model_combined.iterrows():\n",
    "    if(boonull.loc[i,1]):\n",
    "        model_combined.loc[i,'label'] = boo.loc[i,0]\n",
    "    else:\n",
    "        model_combined.loc[i,'label'] = row[row['confident'].split('|')[0]]\n",
    "\n",
    "model_combined['label'] = model_combined.apply(lambda x : x[x['confident'].split('|')[0]], axis = 1)\n",
    "# model_combined['label'] = model_combined.apply(lambda x : x['resnet101_2_steps'] if (x['resnet101_2_stepsprob'] > x['resnet50_3_stepsprob']) else x['resnet50_3_steps'], axis = 1)\n",
    "model_combined['actuals_y'] = data.val_y\n",
    "model_combined['actual_labels'] = model_combined.apply(lambda x : data.classes[int(x['actuals_y'])], axis = 1)\n",
    "model_combined['predicted_labels'] = model_combined.apply(lambda x : data.classes[int(x['label'])], axis = 1)\n",
    "print(accuracy_score(model_combined.actual_labels.values, model_combined.predicted_labels.values))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(model_combined.label.values, learn.data.val_y)\n",
    "print(accuracy_score(model_combined.label.values, learn.data.val_y))\n",
    "print(cm)\n",
    "\n",
    "model_combined.to_csv('result_temp.csv')\n",
    "\n",
    "testr = get_submission_file(learn, ensemble = True)\n",
    "\n",
    "testr[testr['image_id'] == 'ffd889f4b3138459e1203a4190286158a9aaea40.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try other models as well from pretrained batch - better than resnet ones\n",
    "# Try their transformation variants\n",
    "# Progressive resizing of the best model till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train individual networks with progressively increasing image sizes\n",
    "# Incrementally train larger networks with more image size and smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
